{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPMghlRWjLE+KonVJW0kZIg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ag4267research1/Solving-Poisson-s-Equation-with-GNO/blob/main/GNOPDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuraloperator --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ViveZVX1RT",
        "outputId": "bafbb05d-9306-48bc-950d-db49ab98caed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuraloperator\n",
            "  Downloading neuraloperator-2.0.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (0.23.0)\n",
            "Collecting ruamel-yaml (from neuraloperator)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting zencfg (from neuraloperator)\n",
            "  Downloading zencfg-0.6.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting configmypy (from neuraloperator)\n",
            "  Downloading configmypy-0.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting tensorly (from neuraloperator)\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tensorly-torch (from neuraloperator)\n",
            "  Downloading tensorly_torch-0.5.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.15.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from zencfg->neuraloperator) (2.12.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from configmypy->neuraloperator) (8.4.2)\n",
            "Collecting pytest-mock (from configmypy->neuraloperator)\n",
            "  Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (2.9.0.post0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml->neuraloperator)\n",
            "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorly->neuraloperator) (1.16.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->neuraloperator) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2025.11.12)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.19.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (5.0.2)\n",
            "Downloading neuraloperator-2.0.0-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zencfg-0.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading configmypy-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly_torch-0.5.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_mock-3.15.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: ruamel.yaml.clib, tensorly-torch, tensorly, ruamel-yaml, pytest-mock, zencfg, configmypy, neuraloperator\n",
            "Successfully installed configmypy-0.2.0 neuraloperator-2.0.0 pytest-mock-3.15.1 ruamel-yaml-0.18.16 ruamel.yaml.clib-0.2.15 tensorly-0.9.0 tensorly-torch-0.5.0 zencfg-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "# Correct imports:\n",
        "from neuralop.layers.gno_block import GNOBlock\n",
        "from neuralop.data.transforms.normalizers import UnitGaussianNormalizer\n",
        "from neuralop.training import Trainer\n",
        "\n"
      ],
      "metadata": {
        "id": "pY8Z8KJSYoUH"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder in the Colab VM (not Drive)\n",
        "!mkdir -p /content/nonlinear_poisson\n",
        "!cd /content/nonlinear_poisson\n",
        "\n",
        "# Download with progress bar (percentage + speed)\n",
        "!wget --show-progress \\\n",
        "  \"https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\" \\\n",
        "  -O nonlinear_poisson.obj\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K7qfXJfZm8c",
        "outputId": "03fc3aff-0caf-4e59-fe74-90a2e2c2af56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-07 18:59:03--  https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.75, 137.138.52.235, 188.185.43.153, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9608410281 (8.9G) [application/octet-stream]\n",
            "Saving to: ‘nonlinear_poisson.obj’\n",
            "\n",
            "nonlinear_poisson.o 100%[===================>]   8.95G  19.1MB/s    in 8m 2s   \n",
            "\n",
            "2025-12-07 19:07:05 (19.0 MB/s) - ‘nonlinear_poisson.obj’ saved [9608410281/9608410281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show file size\n",
        "!ls -lh nonlinear_poisson.obj"
      ],
      "metadata": {
        "id": "_vuW2krxbHmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b140de35-b44f-46c9-9ba2-356741b06a82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 9.0G Dec  7 19:07 nonlinear_poisson.obj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFnXiiORN4ND",
        "outputId": "530f8d52-ebf4-4ba4-eb7d-b44f0b46704b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    raw_data = pickle.load(f)\n",
        "\n",
        "print(\"Type:\", type(raw_data))\n",
        "print(\"Number of PDE samples:\", len(raw_data))\n",
        "\n",
        "sample = raw_data[0]\n",
        "print(\"Sample keys:\", sample.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnbGFCN7Pc5v",
        "outputId": "6397e2d3-2b73-4b8a-fcfb-b3b8f492db96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Exists? True\n",
            "Type: <class 'list'>\n",
            "Number of PDE samples: 10000\n",
            "Sample keys: dict_keys(['train_points_boundary', 'train_values_boundary', 'train_source_terms_boundary', 'train_bc_boundary', 'train_points_domain', 'train_values_domain', 'train_distances_domain', 'train_source_terms_domain', 'train_bc_domain', 'val_points_boundary', 'val_values_boundary', 'val_source_terms_boundary', 'val_points_domain', 'val_values_domain', 'val_source_terms_domain', 'coefs'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_coefs_dict(coefs_dict):\n",
        "    out_list = []\n",
        "    for k, v in coefs_dict.items():\n",
        "        if isinstance(v, np.ndarray):          # numpy array\n",
        "            out_list.extend(v.reshape(-1).tolist())\n",
        "        elif np.isscalar(v):                   # single float\n",
        "            out_list.append(float(v))\n",
        "        else:\n",
        "            # Unexpected type: ignore or print for debugging\n",
        "            # print(\"Skipping key:\", k, \"value type:\", type(v))\n",
        "            continue\n",
        "    return torch.tensor(out_list, dtype=torch.float32)\n",
        "\n",
        "\n",
        "class NonlinearPoissonDataset(Dataset):\n",
        "    def __init__(self, data_list, split=\"train\"):\n",
        "        self.data_list = data_list\n",
        "        self.split = split\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data_list[idx]\n",
        "\n",
        "        # 1. Coordinates (P,2)\n",
        "        coords = torch.tensor(item[f\"{self.split}_points_domain\"], dtype=torch.float32)\n",
        "\n",
        "        # 2. Forcing (P,) → (P,1)\n",
        "        f = torch.tensor(item[f\"{self.split}_source_terms_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        # 3. Distance to boundary (P,) → (P,1)\n",
        "        d = torch.tensor(item[f\"{self.split}_distances_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        # 4. Flatten geometry coefficients\n",
        "        coefs = flatten_coefs_dict(item[\"coefs\"])            # (C,)\n",
        "        coefs = coefs.unsqueeze(0).expand(coords.shape[0], -1)  # (P, C)\n",
        "\n",
        "        # 5. Stack all features → input X\n",
        "        features = torch.cat([f, d, coefs], dim=-1)          # (P, 1 + 1 + C)\n",
        "\n",
        "        # 6. Solution u (P,) → (P,1)\n",
        "        u = torch.tensor(item[f\"{self.split}_values_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        return coords, features, u"
      ],
      "metadata": {
        "id": "xEDPT03CP1t-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sample[\"coefs\"]))\n",
        "print(sample[\"coefs\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8zlTP1KS4Nq",
        "outputId": "206fffd3-0f54-4837-d4e7-08af0cca95de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'seed': 1, 'c1': np.float32(-0.0007273823), 'c2': np.float32(-0.0042264136), 'r0': 1.0, 'beta': array([-1.1116347 ,  0.66393006], dtype=float32), 'mu_1': array([-0.84975487, -1.102674  ], dtype=float32), 'mu_2': array([ 0.9603709, -1.4707267], dtype=float32), 'b': array([ 0.5957165 ,  0.4740579 , -0.05061221, -0.35185003,  0.6810765 ],\n",
            "      dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(coords0.shape, feats0.shape, u0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vrqMNosTI51",
        "outputId": "40ab44ee-c752-4941-c7d5-eab5103201fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 10000, 2]) torch.Size([4, 10000, 17]) torch.Size([4, 10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple 90/10 split\n",
        "n_total = len(raw_data)\n",
        "n_train = int(0.9 * n_total)\n",
        "train_raw = raw_data[:n_train]\n",
        "val_raw   = raw_data[n_train:]\n",
        "\n",
        "train_ds = NonlinearPoissonDataset(train_raw, split=\"train\")\n",
        "val_ds   = NonlinearPoissonDataset(val_raw,   split=\"val\")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Because every PDE has the same number of points,\n",
        "    default collate would actually work, but this keeps it explicit.\n",
        "    \"\"\"\n",
        "    coords, feats, u = zip(*batch)  # each is list length B\n",
        "\n",
        "    coords = torch.stack(coords, dim=0)  # (B, P, 2)\n",
        "    feats  = torch.stack(feats,  dim=0)  # (B, P, C_in)\n",
        "    u      = torch.stack(u,      dim=0)  # (B, P, 1)\n",
        "\n",
        "    return coords, feats, u\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,\n",
        "                          num_workers=2, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False,\n",
        "                          num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(\"coords batch:\", coords0.shape)\n",
        "print(\"features batch:\", feats0.shape)\n",
        "print(\"u batch:\", u0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0SLm-gkQjxY",
        "outputId": "7cd5a940-b299-4653-e3ce-f99f025d46a2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coords batch: torch.Size([4, 10000, 2])\n",
            "features batch: torch.Size([4, 10000, 17])\n",
            "u batch: torch.Size([4, 10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "pHc5qDkgcA0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GNOPoissonModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Pure Graph Neural Operator built from GNOBlocks.\n",
        "    Maps features on domain points -> solution u(x) on same points.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, hidden_channels=64,\n",
        "                 coord_dim=2, radius=0.25, n_layers=3):\n",
        "        super().__init__()\n",
        "\n",
        "        self.coord_dim = coord_dim\n",
        "\n",
        "        layers = []\n",
        "        c_in = in_channels\n",
        "\n",
        "        # First layer: in -> hidden\n",
        "        layers.append(\n",
        "            GNOBlock(\n",
        "                in_channels=c_in,\n",
        "                out_channels=hidden_channels,\n",
        "                coord_dim=coord_dim,\n",
        "                radius=radius,\n",
        "                transform_type=\"nonlinear\",\n",
        "                reduction=\"sum\",\n",
        "                use_open3d_neighbor_search=False ,\n",
        "\n",
        "            )\n",
        "        )\n",
        "        c_in = hidden_channels\n",
        "\n",
        "        # Middle hidden layers\n",
        "        for _ in range(n_layers - 2):\n",
        "            layers.append(\n",
        "                GNOBlock(\n",
        "                    in_channels=c_in,\n",
        "                    out_channels=hidden_channels,\n",
        "                    coord_dim=coord_dim,\n",
        "                    radius=radius,\n",
        "                    transform_type=\"nonlinear\",\n",
        "                    reduction=\"sum\",\n",
        "                    use_open3d_neighbor_search=False ,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Last layer: hidden -> 1 (solution)\n",
        "        layers.append(\n",
        "            GNOBlock(\n",
        "                in_channels=hidden_channels,\n",
        "                out_channels=1,\n",
        "                coord_dim=coord_dim,\n",
        "                radius=radius,\n",
        "                transform_type=\"linear\",\n",
        "                reduction=\"sum\",\n",
        "                use_open3d_neighbor_search=False ,\n",
        "            )\n",
        "        )\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, coords, feats):\n",
        "        \"\"\"\n",
        "        coords: (B, P, 2)\n",
        "        feats:  (B, P, C_in)\n",
        "        returns: (B, P, 1)\n",
        "        \"\"\"\n",
        "        x = feats\n",
        "        for layer in self.layers:\n",
        "            # Most recent GNOBlock API: forward(x, coords, query_coords=None)\n",
        "            x = layer(x, coords)\n",
        "            x = F.gelu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "vXMAwi90cDZw"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "in_channels = feats0.shape[-1]\n",
        "print(\"Input feature channels:\", in_channels)\n",
        "\n",
        "model = GNOPoissonModel(\n",
        "    in_channels=in_channels,\n",
        "    hidden_channels=64,\n",
        "    coord_dim=2,\n",
        "    radius=0.2,\n",
        "    n_layers=3,\n",
        ").to(device)\n",
        "\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "id": "vlQVgOGEUUrB",
        "outputId": "51929c1a-b2f0-45e9-e52e-41eb7b5bc807",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature channels: 17\n",
            "GNOPoissonModel(\n",
            "  (layers): ModuleList(\n",
            "    (0): GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=273, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (1): GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=320, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=1, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    n_samples = 0\n",
        "\n",
        "    for coords, feats, u in loader:\n",
        "        coords = coords.to(device)\n",
        "        feats  = feats.to(device)\n",
        "        u      = u.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            u_pred = model(coords, feats)\n",
        "            loss = criterion(u_pred, u)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        batch_size = coords.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        n_samples += batch_size\n",
        "\n",
        "    return total_loss / n_samples\n",
        "\n",
        "\n",
        "n_epochs = 20  # increase to 100+ once it works\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train_loss = run_epoch(train_loader, train=True)\n",
        "    val_loss   = run_epoch(val_loader,   train=False)\n",
        "    print(f\"[Epoch {epoch:03d}] train MSE: {train_loss:.4e}   val MSE: {val_loss:.4e}\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 8. Quick sanity check on one validation batch\n",
        "# ============================================================\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    coords, feats, u_true = next(iter(val_loader))\n",
        "    coords = coords.to(device)\n",
        "    feats  = feats.to(device)\n",
        "    u_true = u_true.to(device)\n",
        "\n",
        "    u_pred = model(coords, feats)\n",
        "    mse = F.mse_loss(u_pred, u_true).item()\n",
        "    print(\"One-batch validation MSE:\", mse)"
      ],
      "metadata": {
        "id": "q4DqxcS3U2mo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}