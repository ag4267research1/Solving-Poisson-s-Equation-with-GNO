{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNu3p8C5g0UWvwwQK/AsIy4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ag4267research1/Solving-Poisson-s-Equation-with-GNO/blob/main/GNOPDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuraloperator --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ViveZVX1RT",
        "outputId": "bafbb05d-9306-48bc-950d-db49ab98caed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuraloperator\n",
            "  Downloading neuraloperator-2.0.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (0.23.0)\n",
            "Collecting ruamel-yaml (from neuraloperator)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting zencfg (from neuraloperator)\n",
            "  Downloading zencfg-0.6.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting configmypy (from neuraloperator)\n",
            "  Downloading configmypy-0.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting tensorly (from neuraloperator)\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tensorly-torch (from neuraloperator)\n",
            "  Downloading tensorly_torch-0.5.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.15.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from zencfg->neuraloperator) (2.12.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from configmypy->neuraloperator) (8.4.2)\n",
            "Collecting pytest-mock (from configmypy->neuraloperator)\n",
            "  Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (2.9.0.post0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml->neuraloperator)\n",
            "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorly->neuraloperator) (1.16.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.46.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->neuraloperator) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2025.11.12)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.19.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (5.0.2)\n",
            "Downloading neuraloperator-2.0.0-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zencfg-0.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading configmypy-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly_torch-0.5.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_mock-3.15.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: ruamel.yaml.clib, tensorly-torch, tensorly, ruamel-yaml, pytest-mock, zencfg, configmypy, neuraloperator\n",
            "Successfully installed configmypy-0.2.0 neuraloperator-2.0.0 pytest-mock-3.15.1 ruamel-yaml-0.18.16 ruamel.yaml.clib-0.2.15 tensorly-0.9.0 tensorly-torch-0.5.0 zencfg-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import inspect\n",
        "\n",
        "# Correct imports:\n",
        "from neuralop.layers.gno_block import GNOBlock\n",
        "from neuralop.data.transforms.normalizers import UnitGaussianNormalizer\n",
        "from neuralop.training import Trainer\n",
        "\n"
      ],
      "metadata": {
        "id": "pY8Z8KJSYoUH"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder in the Colab VM (not Drive)\n",
        "!mkdir -p /content/nonlinear_poisson\n",
        "!cd /content/nonlinear_poisson\n",
        "\n",
        "# Download with progress bar (percentage + speed)\n",
        "!wget --show-progress \\\n",
        "  \"https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\" \\\n",
        "  -O nonlinear_poisson.obj\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K7qfXJfZm8c",
        "outputId": "03fc3aff-0caf-4e59-fe74-90a2e2c2af56"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-07 18:59:03--  https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.75, 137.138.52.235, 188.185.43.153, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9608410281 (8.9G) [application/octet-stream]\n",
            "Saving to: ‘nonlinear_poisson.obj’\n",
            "\n",
            "nonlinear_poisson.o 100%[===================>]   8.95G  19.1MB/s    in 8m 2s   \n",
            "\n",
            "2025-12-07 19:07:05 (19.0 MB/s) - ‘nonlinear_poisson.obj’ saved [9608410281/9608410281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show file size\n",
        "!ls -lh nonlinear_poisson.obj"
      ],
      "metadata": {
        "id": "_vuW2krxbHmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b140de35-b44f-46c9-9ba2-356741b06a82"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 9.0G Dec  7 19:07 nonlinear_poisson.obj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFnXiiORN4ND",
        "outputId": "530f8d52-ebf4-4ba4-eb7d-b44f0b46704b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    raw_data = pickle.load(f)\n",
        "\n",
        "print(\"Type:\", type(raw_data))\n",
        "print(\"Number of PDE samples:\", len(raw_data))\n",
        "\n",
        "sample = raw_data[0]\n",
        "print(\"Sample keys:\", sample.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnbGFCN7Pc5v",
        "outputId": "6397e2d3-2b73-4b8a-fcfb-b3b8f492db96"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Exists? True\n",
            "Type: <class 'list'>\n",
            "Number of PDE samples: 10000\n",
            "Sample keys: dict_keys(['train_points_boundary', 'train_values_boundary', 'train_source_terms_boundary', 'train_bc_boundary', 'train_points_domain', 'train_values_domain', 'train_distances_domain', 'train_source_terms_domain', 'train_bc_domain', 'val_points_boundary', 'val_values_boundary', 'val_source_terms_boundary', 'val_points_domain', 'val_values_domain', 'val_source_terms_domain', 'coefs'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def flatten_coefs_dict(coefs_dict):\n",
        "    out_list = []\n",
        "    for k, v in coefs_dict.items():\n",
        "        if isinstance(v, np.ndarray):          # numpy array\n",
        "            out_list.extend(v.reshape(-1).tolist())\n",
        "        elif np.isscalar(v):                   # single float\n",
        "            out_list.append(float(v))\n",
        "        else:\n",
        "            # Unexpected type: ignore or print for debugging\n",
        "            # print(\"Skipping key:\", k, \"value type:\", type(v))\n",
        "            continue\n",
        "    return torch.tensor(out_list, dtype=torch.float32)\n",
        "\n",
        "\n",
        "class NonlinearPoissonDataset(Dataset):\n",
        "    def __init__(self, data_list, split=\"train\"):\n",
        "        self.data_list = data_list\n",
        "        self.split = split\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data_list[idx]\n",
        "\n",
        "        # 1. Coordinates (P,2)\n",
        "        coords = torch.tensor(item[f\"{self.split}_points_domain\"], dtype=torch.float32)\n",
        "\n",
        "        # 2. Forcing (P,) → (P,1)\n",
        "        f = torch.tensor(item[f\"{self.split}_source_terms_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        # 3. Distance to boundary (P,) → (P,1)\n",
        "        d = torch.tensor(item[f\"{self.split}_distances_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        # 4. Flatten geometry coefficients\n",
        "        coefs = flatten_coefs_dict(item[\"coefs\"])            # (C,)\n",
        "        coefs = coefs.unsqueeze(0).expand(coords.shape[0], -1)  # (P, C)\n",
        "\n",
        "        # 5. Stack all features → input X\n",
        "        features = torch.cat([f, d, coefs], dim=-1)          # (P, 1 + 1 + C)\n",
        "\n",
        "        # 6. Solution u (P,) → (P,1)\n",
        "        u = torch.tensor(item[f\"{self.split}_values_domain\"], dtype=torch.float32).unsqueeze(-1)\n",
        "\n",
        "        return coords, features, u"
      ],
      "metadata": {
        "id": "xEDPT03CP1t-"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sample[\"coefs\"]))\n",
        "print(sample[\"coefs\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8zlTP1KS4Nq",
        "outputId": "206fffd3-0f54-4837-d4e7-08af0cca95de"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'seed': 1, 'c1': np.float32(-0.0007273823), 'c2': np.float32(-0.0042264136), 'r0': 1.0, 'beta': array([-1.1116347 ,  0.66393006], dtype=float32), 'mu_1': array([-0.84975487, -1.102674  ], dtype=float32), 'mu_2': array([ 0.9603709, -1.4707267], dtype=float32), 'b': array([ 0.5957165 ,  0.4740579 , -0.05061221, -0.35185003,  0.6810765 ],\n",
            "      dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(coords0.shape, feats0.shape, u0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vrqMNosTI51",
        "outputId": "40ab44ee-c752-4941-c7d5-eab5103201fb"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 10000, 2]) torch.Size([4, 10000, 17]) torch.Size([4, 10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple 90/10 split\n",
        "n_total = len(raw_data)\n",
        "n_train = int(0.9 * n_total)\n",
        "train_raw = raw_data[:n_train]\n",
        "val_raw   = raw_data[n_train:]\n",
        "\n",
        "train_ds = NonlinearPoissonDataset(train_raw, split=\"train\")\n",
        "val_ds   = NonlinearPoissonDataset(val_raw,   split=\"val\")\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Because every PDE has the same number of points,\n",
        "    default collate would actually work, but this keeps it explicit.\n",
        "    \"\"\"\n",
        "    coords, feats, u = zip(*batch)  # each is list length B\n",
        "\n",
        "    coords = torch.stack(coords, dim=0)  # (B, P, 2)\n",
        "    feats  = torch.stack(feats,  dim=0)  # (B, P, C_in)\n",
        "    u      = torch.stack(u,      dim=0)  # (B, P, 1)\n",
        "\n",
        "    return coords, feats, u\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True,\n",
        "                          num_workers=2, collate_fn=collate_fn)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=4, shuffle=False,\n",
        "                          num_workers=2, collate_fn=collate_fn)\n",
        "\n",
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(\"coords batch:\", coords0.shape)\n",
        "print(\"features batch:\", feats0.shape)\n",
        "print(\"u batch:\", u0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0SLm-gkQjxY",
        "outputId": "7cd5a940-b299-4653-e3ce-f99f025d46a2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coords batch: torch.Size([4, 10000, 2])\n",
            "features batch: torch.Size([4, 10000, 17])\n",
            "u batch: torch.Size([4, 10000, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "pHc5qDkgcA0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from neuralop.layers.gno_block import GNOBlock\n",
        "\n",
        "\n",
        "class GNOPoissonModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=17,          # your dataset feature count\n",
        "        hidden_channels=64,\n",
        "        out_channels=1,\n",
        "        n_layers=4,\n",
        "        radius=0.1,\n",
        "        coord_dim=2\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "\n",
        "        # First GNO layer\n",
        "        self.layers.append(\n",
        "            GNOBlock(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=hidden_channels,\n",
        "                coord_dim=coord_dim,\n",
        "                radius=radius,\n",
        "                use_open3d_neighbor_search=False   # IMPORTANT FIX\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Middle GNO layers\n",
        "        for _ in range(n_layers - 2):\n",
        "            self.layers.append(\n",
        "                GNOBlock(\n",
        "                    in_channels=hidden_channels,\n",
        "                    out_channels=hidden_channels,\n",
        "                    coord_dim=coord_dim,\n",
        "                    radius=radius,\n",
        "                    use_open3d_neighbor_search=False  # IMPORTANT FIX\n",
        "                )\n",
        "            )\n",
        "\n",
        "        # Last GNO layer\n",
        "        self.layers.append(\n",
        "            GNOBlock(\n",
        "                in_channels=hidden_channels,\n",
        "                out_channels=out_channels,\n",
        "                coord_dim=coord_dim,\n",
        "                radius=radius,\n",
        "                use_open3d_neighbor_search=False  # IMPORTANT FIX\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Optional MLP head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(out_channels, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, out_channels)\n",
        "        )\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "vXMAwi90cDZw"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, coords, feats):\n",
        "    \"\"\"\n",
        "    coords: (B, N, 2)\n",
        "    feats:  (B, N, C)\n",
        "    \"\"\"\n",
        "\n",
        "    # If missing batch dimension → add it\n",
        "    if coords.ndim == 2:\n",
        "        coords = coords.unsqueeze(0)\n",
        "    if feats.ndim == 2:\n",
        "        feats = feats.unsqueeze(0)\n",
        "\n",
        "    # GNO expects y, x, f_y shape = (B, N, *)\n",
        "    y = coords\n",
        "    x = coords\n",
        "    h = feats\n",
        "\n",
        "    for layer in self.layers:\n",
        "        h = layer(y, x, h)\n",
        "\n",
        "    return self.head(h)"
      ],
      "metadata": {
        "id": "ASvsh-ssZNQC"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "in_channels = feats0.shape[-1]\n",
        "print(\"Input feature channels:\", in_channels)\n",
        "\n",
        "model = GNOPoissonModel(\n",
        "    in_channels=in_channels,\n",
        "    hidden_channels=64,\n",
        "    coord_dim=2,\n",
        "    radius=0.2,\n",
        "    n_layers=3,\n",
        ").to(device)\n",
        "\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlQVgOGEUUrB",
        "outputId": "e815c471-9e34-43d7-c392-2cfe4ae5ae29"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature channels: 17\n",
            "GNOPoissonModel(\n",
            "  (layers): ModuleList(\n",
            "    (0-1): 2 x GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=64, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (2): GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=1, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=1, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "criterion = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "q4DqxcS3U2mo"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    n_samples = 0\n",
        "\n",
        "    for coords, feats, u in loader:\n",
        "        coords = coords.to(device)\n",
        "        feats  = feats.to(device)\n",
        "        u      = u.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            u_pred = model(coords, feats)\n",
        "            loss = criterion(u_pred, u)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        batch_size = coords.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        n_samples += batch_size\n",
        "\n",
        "    return total_loss / n_samples\n"
      ],
      "metadata": {
        "id": "J2jV_w33VDXh"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "\n",
        "print(\"coords0\", type(coords0), coords0.shape)\n",
        "print(\"feats0\", type(feats0))\n",
        "print(\"u0\", type(u0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP0npWdmXUv-",
        "outputId": "5b5bc656-59c6-45b5-9fc0-69c8f95fe629"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coords0 <class 'torch.Tensor'> torch.Size([4, 10000, 2])\n",
            "feats0 <class 'torch.Tensor'>\n",
            "u0 <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GNOBlock.forward signature:\\n\")\n",
        "print(inspect.signature(GNOBlock.forward))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxdaaMNgWLO8",
        "outputId": "774c0190-f0ba-4a95-9b7b-36dfcc12dfcb"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNOBlock.forward signature:\n",
            "\n",
            "(self, y, x, f_y=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inspect.getsource(GNOBlock.forward))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shbuh3qiWgeT",
        "outputId": "e4fe657b-f978-4b42-bf4a-7e3d39fe3547"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def forward(self, y, x, f_y=None):\n",
            "        \"\"\"Compute a GNO neighbor search and kernel integral transform.\n",
            "\n",
            "        Parameters\n",
            "        ----------\n",
            "        y : torch.Tensor of shape [n, d1]\n",
            "            n points of dimension d1 specifying\n",
            "            the space to integrate over.\n",
            "            If batched, these must remain constant\n",
            "            over the whole batch so no batch dim is needed.\n",
            "        x : torch.Tensor of shape [m, d1], default None\n",
            "            m points of dimension d1 over which the\n",
            "            output function is defined. Must share domain\n",
            "            with y\n",
            "        f_y : torch.Tensor of shape [batch, n, d2] or [n, d2], default None\n",
            "            Function to integrate the kernel against defined\n",
            "            on the points y. The kernel is assumed diagonal\n",
            "            hence its output shape must be d3 for the transforms\n",
            "            (b) or (d). If None, (a) is computed.\n",
            "\n",
            "        Output\n",
            "        ----------\n",
            "        out_features : torch.Tensor of shape [batch, m, d3] or [m, d3]\n",
            "            Output function given on the points x.\n",
            "            d4 is the output size of the kernel k.\n",
            "        \"\"\"\n",
            "        if f_y is not None:\n",
            "            if f_y.ndim == 3 and f_y.shape[0] == -1:\n",
            "                f_y = f_y.squeeze(0)\n",
            "\n",
            "        neighbors_dict = self.neighbor_search(data=y, queries=x, radius=self.radius)\n",
            "\n",
            "        if self.pos_embedding is not None:\n",
            "            y_embed = self.pos_embedding(y)\n",
            "            x_embed = self.pos_embedding(x)\n",
            "        else:\n",
            "            y_embed = y\n",
            "            x_embed = x\n",
            "\n",
            "        out_features = self.integral_transform(\n",
            "            y=y_embed, x=x_embed, neighbors=neighbors_dict, f_y=f_y\n",
            "        )\n",
            "\n",
            "        return out_features\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inspect.signature(GNOBlock.forward))\n",
        "print(inspect.getsource(GNOBlock.forward))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZSQHPeyWqtf",
        "outputId": "3304ceae-2eda-4f2b-966c-fbaeef4026fd"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(self, y, x, f_y=None)\n",
            "    def forward(self, y, x, f_y=None):\n",
            "        \"\"\"Compute a GNO neighbor search and kernel integral transform.\n",
            "\n",
            "        Parameters\n",
            "        ----------\n",
            "        y : torch.Tensor of shape [n, d1]\n",
            "            n points of dimension d1 specifying\n",
            "            the space to integrate over.\n",
            "            If batched, these must remain constant\n",
            "            over the whole batch so no batch dim is needed.\n",
            "        x : torch.Tensor of shape [m, d1], default None\n",
            "            m points of dimension d1 over which the\n",
            "            output function is defined. Must share domain\n",
            "            with y\n",
            "        f_y : torch.Tensor of shape [batch, n, d2] or [n, d2], default None\n",
            "            Function to integrate the kernel against defined\n",
            "            on the points y. The kernel is assumed diagonal\n",
            "            hence its output shape must be d3 for the transforms\n",
            "            (b) or (d). If None, (a) is computed.\n",
            "\n",
            "        Output\n",
            "        ----------\n",
            "        out_features : torch.Tensor of shape [batch, m, d3] or [m, d3]\n",
            "            Output function given on the points x.\n",
            "            d4 is the output size of the kernel k.\n",
            "        \"\"\"\n",
            "        if f_y is not None:\n",
            "            if f_y.ndim == 3 and f_y.shape[0] == -1:\n",
            "                f_y = f_y.squeeze(0)\n",
            "\n",
            "        neighbors_dict = self.neighbor_search(data=y, queries=x, radius=self.radius)\n",
            "\n",
            "        if self.pos_embedding is not None:\n",
            "            y_embed = self.pos_embedding(y)\n",
            "            x_embed = self.pos_embedding(x)\n",
            "        else:\n",
            "            y_embed = y\n",
            "            x_embed = x\n",
            "\n",
            "        out_features = self.integral_transform(\n",
            "            y=y_embed, x=x_embed, neighbors=neighbors_dict, f_y=f_y\n",
            "        )\n",
            "\n",
            "        return out_features\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 20  # increase to 100+ once it works\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "    train_loss = run_epoch(train_loader, train=True)\n",
        "    val_loss   = run_epoch(val_loader,   train=False)\n",
        "    print(f\"[Epoch {epoch:03d}] train MSE: {train_loss:.4e}   val MSE: {val_loss:.4e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "FbKbI36cVG5h",
        "outputId": "087e10ef-7a62-43d6-e9e4-b1970c595a27"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "X1 and X2 must have the same number of columns. X1: 2 X2: 17",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3045055540.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mval_loss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mrun_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"[Epoch {epoch:03d}] train MSE: {train_loss:.4e}   val MSE: {val_loss:.4e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3537653644.py\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(loader, train)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mu_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3625187359.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coords, feats)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# ******* CRITICAL FIX *******\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# <<< MUST PASS coords TWICE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neuralop/layers/gno_block.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y, x, f_y)\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0mf_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mneighbors_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbor_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_embedding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neuralop/layers/neighbor_search.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, queries, radius)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mradius\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/neuralop/layers/neighbor_search.py\u001b[0m in \u001b[0;36mnative_neighbor_search\u001b[0;34m(data, queries, radius, return_norm)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;31m# compute pairwise distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mall_dists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# shaped num query points x num data points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m     \u001b[0;31m# keep zero-distance points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0meps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1459\u001b[0m         )\n\u001b[1;32m   1460\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"use_mm_for_euclid_dist_if_necessary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1462\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"use_mm_for_euclid_dist\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: X1 and X2 must have the same number of columns. X1: 2 X2: 17"
          ]
        }
      ]
    }
  ]
}