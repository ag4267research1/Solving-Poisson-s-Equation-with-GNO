{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPBUiUulWL1gocZRHP8ed6s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ag4267research1/Solving-Poisson-s-Equation-with-GNO/blob/main/GNOPDE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neuraloperator --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-ViveZVX1RT",
        "outputId": "fd55533a-e5d7-4b4c-b66f-3111033343cc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuraloperator\n",
            "  Downloading neuraloperator-2.0.0-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (0.23.1)\n",
            "Collecting ruamel-yaml (from neuraloperator)\n",
            "  Downloading ruamel.yaml-0.18.16-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting zencfg (from neuraloperator)\n",
            "  Downloading zencfg-0.6.0-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting configmypy (from neuraloperator)\n",
            "  Downloading configmypy-0.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting tensorly (from neuraloperator)\n",
            "  Downloading tensorly-0.9.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting tensorly-torch (from neuraloperator)\n",
            "  Downloading tensorly_torch-0.5.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (2.0.2)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from neuraloperator) (3.15.1)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (from zencfg->neuraloperator) (2.12.3)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.12/dist-packages (from configmypy->neuraloperator) (8.4.2)\n",
            "Collecting pytest-mock (from configmypy->neuraloperator)\n",
            "  Downloading pytest_mock-3.15.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (4.61.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->neuraloperator) (2.9.0.post0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel-yaml->neuraloperator)\n",
            "  Downloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from tensorly->neuraloperator) (1.16.3)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (8.3.1)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (3.1.45)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.5.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (5.29.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.32.4)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (2.47.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.8 in /usr/local/lib/python3.12/dist-packages (from wandb->neuraloperator) (4.15.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic->zencfg->neuraloperator) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->neuraloperator) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.0.0->wandb->neuraloperator) (2025.11.12)\n",
            "Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.3.0)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (1.6.0)\n",
            "Requirement already satisfied: pygments>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from pytest->configmypy->neuraloperator) (2.19.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->neuraloperator) (5.0.2)\n",
            "Downloading neuraloperator-2.0.0-py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m248.6/248.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zencfg-0.6.0-py3-none-any.whl (31 kB)\n",
            "Downloading configmypy-0.2.0-py3-none-any.whl (14 kB)\n",
            "Downloading ruamel.yaml-0.18.16-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly-0.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m113.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorly_torch-0.5.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ruamel_yaml_clib-0.2.15-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (788 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_mock-3.15.1-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: ruamel.yaml.clib, tensorly-torch, tensorly, ruamel-yaml, pytest-mock, zencfg, configmypy, neuraloperator\n",
            "Successfully installed configmypy-0.2.0 neuraloperator-2.0.0 pytest-mock-3.15.1 ruamel-yaml-0.18.16 ruamel.yaml.clib-0.2.15 tensorly-0.9.0 tensorly-torch-0.5.0 zencfg-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import inspect\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Correct imports:\n",
        "from neuralop.layers.gno_block import GNOBlock\n",
        "from neuralop.data.transforms.normalizers import UnitGaussianNormalizer\n",
        "from neuralop.training import Trainer\n",
        "\n"
      ],
      "metadata": {
        "id": "pY8Z8KJSYoUH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder in the Colab VM (not Drive)\n",
        "!mkdir -p /content/nonlinear_poisson\n",
        "!cd /content/nonlinear_poisson\n",
        "\n",
        "# Download with progress bar (percentage + speed)\n",
        "!wget --show-progress \\\n",
        "  \"https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\" \\\n",
        "  -O nonlinear_poisson.obj\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8K7qfXJfZm8c",
        "outputId": "7321235e-b3ce-48b7-8a48-fb3215785f52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-09 11:08:44--  https://zenodo.org/records/15001788/files/nonlinear_poisson.obj?download=1\n",
            "Resolving zenodo.org (zenodo.org)... 188.185.48.75, 188.185.43.153, 137.138.52.235, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.185.48.75|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9608410281 (8.9G) [application/octet-stream]\n",
            "Saving to: â€˜nonlinear_poisson.objâ€™\n",
            "\n",
            "nonlinear_poisson.o 100%[===================>]   8.95G  1.35MB/s    in 2h 15m  \n",
            "\n",
            "2025-12-09 13:24:06 (1.13 MB/s) - â€˜nonlinear_poisson.objâ€™ saved [9608410281/9608410281]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show file size\n",
        "!ls -lh nonlinear_poisson.obj"
      ],
      "metadata": {
        "id": "_vuW2krxbHmD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee42fd1-e7ba-4dce-e292-e42fb599b5a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 9.0G Dec  9 13:24 nonlinear_poisson.obj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFnXiiORN4ND",
        "outputId": "c523d133-bc1a-43bd-9066-11b3507af965"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exists? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "DATA_PATH = \"/content/nonlinear_poisson.obj\"\n",
        "print(\"Exists?\", os.path.exists(DATA_PATH))\n",
        "\n",
        "with open(DATA_PATH, \"rb\") as f:\n",
        "    raw_data = pickle.load(f)\n",
        "\n",
        "print(\"Type:\", type(raw_data))\n",
        "print(\"Number of PDE samples:\", len(raw_data))\n",
        "\n",
        "sample = raw_data[0]\n",
        "print(\"Sample keys:\", sample.keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnbGFCN7Pc5v",
        "outputId": "c1698f5f-9dc4-4b25-9e6f-d96e306326b2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Exists? True\n",
            "Type: <class 'list'>\n",
            "Number of PDE samples: 10000\n",
            "Sample keys: dict_keys(['train_points_boundary', 'train_values_boundary', 'train_source_terms_boundary', 'train_bc_boundary', 'train_points_domain', 'train_values_domain', 'train_distances_domain', 'train_source_terms_domain', 'train_bc_domain', 'val_points_boundary', 'val_values_boundary', 'val_source_terms_boundary', 'val_points_domain', 'val_values_domain', 'val_source_terms_domain', 'coefs'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_coefs_dict(coefs_dict):\n",
        "    \"\"\"Flatten geometry coefficient dict safely and always return valid tensor.\"\"\"\n",
        "    out_list = []\n",
        "    for k, v in coefs_dict.items():\n",
        "        if isinstance(v, np.ndarray):\n",
        "            out_list.extend(v.reshape(-1).astype(float).tolist())\n",
        "        elif np.isscalar(v):\n",
        "            out_list.append(float(v))\n",
        "        else:\n",
        "            # Ignore unknown items but DO NOT break shape consistency\n",
        "            continue\n",
        "\n",
        "    if len(out_list) == 0:\n",
        "        # fallback: one dummy coef to preserve tensor shape\n",
        "        out_list = [0.0]\n",
        "\n",
        "    return torch.tensor(out_list, dtype=torch.float32)\n",
        "\n",
        "\n",
        "class NonlinearPoissonDataset(Dataset):\n",
        "    def __init__(self, data_list, split=\"train\", n_points=None):\n",
        "        \"\"\"\n",
        "        n_points: None â†’ use all points\n",
        "                  int  â†’ randomly sample that many points per item\n",
        "        \"\"\"\n",
        "        self.data_list = data_list\n",
        "        self.split = split\n",
        "        self.n_points = n_points\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data_list[idx]\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Load raw arrays\n",
        "        # ----------------------------------------------------------\n",
        "        coords = item[f\"{self.split}_points_domain\"]        # (P,2)\n",
        "        f      = item[f\"{self.split}_source_terms_domain\"]  # (P,)\n",
        "        d      = item[f\"{self.split}_distances_domain\"]     # (P,)\n",
        "        u      = item[f\"{self.split}_values_domain\"]        # (P,)\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # ðŸ”¥ Optional point subsampling\n",
        "        # ----------------------------------------------------------\n",
        "        P = coords.shape[0]\n",
        "        if (self.n_points is not None) and (self.n_points < P):\n",
        "            idxs = np.random.choice(P, self.n_points, replace=False)\n",
        "            coords = coords[idxs]\n",
        "            f      = f[idxs]\n",
        "            d      = d[idxs]\n",
        "            u      = u[idxs]\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Convert to torch tensors (always ensure correct dimensionality)\n",
        "        # ----------------------------------------------------------\n",
        "        coords = torch.as_tensor(coords, dtype=torch.float32)\n",
        "\n",
        "        f = torch.as_tensor(f, dtype=torch.float32).reshape(-1, 1)\n",
        "        d = torch.as_tensor(d, dtype=torch.float32).reshape(-1, 1)\n",
        "        u = torch.as_tensor(u, dtype=torch.float32).reshape(-1, 1)\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Geometry coefficients (always produce consistent C)\n",
        "        # ----------------------------------------------------------\n",
        "        coefs = flatten_coefs_dict(item[\"coefs\"])           # (C,)\n",
        "        coefs = coefs.unsqueeze(0).expand(coords.shape[0], -1)\n",
        "\n",
        "        # ----------------------------------------------------------\n",
        "        # Stack features â†’ (P, Ctotal)   where Ctotal = 1 + 1 + C\n",
        "        # ----------------------------------------------------------\n",
        "        try:\n",
        "            features = torch.cat([f, d, coefs], dim=-1)\n",
        "        except Exception:\n",
        "            print(\"DEBUG shapes:\")\n",
        "            print(\"coords:\", coords.shape)\n",
        "            print(\"f:\", f.shape)\n",
        "            print(\"d:\", d.shape)\n",
        "            print(\"coefs:\", coefs.shape)\n",
        "            raise\n",
        "\n",
        "        # Output: no batch dimension â†’ DataLoader adds it automatically\n",
        "        return coords, features, u\n"
      ],
      "metadata": {
        "id": "xEDPT03CP1t-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(sample[\"coefs\"]))\n",
        "print(sample[\"coefs\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8zlTP1KS4Nq",
        "outputId": "0d8fb4be-35d4-4af1-b0bf-fd30630ab763"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'seed': 1, 'c1': np.float32(-0.0007273823), 'c2': np.float32(-0.0042264136), 'r0': 1.0, 'beta': array([-1.1116347 ,  0.66393006], dtype=float32), 'mu_1': array([-0.84975487, -1.102674  ], dtype=float32), 'mu_2': array([ 0.9603709, -1.4707267], dtype=float32), 'b': array([ 0.5957165 ,  0.4740579 , -0.05061221, -0.35185003,  0.6810765 ],\n",
            "      dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple 90/10 split\n",
        "n_total = len(raw_data)\n",
        "n_train = int(0.9 * n_total)\n",
        "train_raw = raw_data[:n_train]\n",
        "val_raw   = raw_data[n_train:]\n",
        "\n",
        "# ðŸ”¥ raw_data does NOT have \"val_points_domain\" keys â†’ must use split=\"train\"\n",
        "train_ds = NonlinearPoissonDataset(train_raw, split=\"train\", n_points=128)\n",
        "val_ds   = NonlinearPoissonDataset(val_raw,   split=\"train\", n_points=128)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    Explicit collate for safety.\n",
        "    \"\"\"\n",
        "    coords, feats, u = zip(*batch)\n",
        "\n",
        "    coords = torch.stack(coords, dim=0)  # (B, P, 2)\n",
        "    feats  = torch.stack(feats,  dim=0)  # (B, P, C)\n",
        "    u      = torch.stack(u,      dim=0)  # (B, P, 1)\n",
        "\n",
        "    return coords, feats, u\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=4, shuffle=True,\n",
        "    num_workers=2, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=4, shuffle=False,\n",
        "    num_workers=2, collate_fn=collate_fn\n",
        ")\n",
        "\n",
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(\"coords batch:\", coords0.shape)\n",
        "print(\"features batch:\", feats0.shape)\n",
        "print(\"u batch:\", u0.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0SLm-gkQjxY",
        "outputId": "45e85e98-35ca-4add-aa87-81db3ed69394"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coords batch: torch.Size([4, 128, 2])\n",
            "features batch: torch.Size([4, 128, 17])\n",
            "u batch: torch.Size([4, 128, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "pHc5qDkgcA0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "class GNOPoissonModel(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels=17,      # number of input features per point\n",
        "        hidden_channels=64,  # internal GNO width\n",
        "        out_channels=1,      # final scalar u(x)\n",
        "        n_layers=4,\n",
        "        radius=0.2,\n",
        "        coord_dim=2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1) Project raw features (17) -> hidden_channels\n",
        "        self.input_proj = nn.Linear(in_channels, hidden_channels)\n",
        "\n",
        "        # 2) Pure GNO stack, all with same in/out = hidden_channels\n",
        "        gno_layers = []\n",
        "        for _ in range(n_layers):\n",
        "            gno_layers.append(\n",
        "                GNOBlock(\n",
        "                    in_channels=hidden_channels,\n",
        "                    out_channels=hidden_channels,\n",
        "                    coord_dim=coord_dim,\n",
        "                    radius=radius,\n",
        "                    use_open3d_neighbor_search=False,\n",
        "                )\n",
        "            )\n",
        "        self.gno_layers = nn.ModuleList(gno_layers)\n",
        "\n",
        "        # 3) Pointwise head hidden_channels -> 1\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(hidden_channels, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, out_channels),\n",
        "        )\n",
        "\n",
        "    # ------------------------------------------------------------------\n",
        "    #            ðŸ”¥ Completely custom, batch-safe forward\n",
        "    # ------------------------------------------------------------------\n",
        "    def forward(self, coords, feats):\n",
        "        \"\"\"\n",
        "        coords : (B, N, 2) or (N, 2)\n",
        "        feats  : (B, N, C_in) or (N, C_in)\n",
        "        Returns:\n",
        "            u_pred : (B, N, 1)\n",
        "        \"\"\"\n",
        "\n",
        "        # Ensure batch dimension\n",
        "        if coords.ndim == 2:   # (N, 2)\n",
        "            coords = coords.unsqueeze(0)\n",
        "        if feats.ndim == 2:    # (N, C)\n",
        "            feats = feats.unsqueeze(0)\n",
        "\n",
        "        B, N, _ = coords.shape\n",
        "        _, Nf, Cin = feats.shape\n",
        "        assert N == Nf, f\"coords and feats mismatch: {coords.shape} vs {feats.shape}\"\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        # IMPORTANT:\n",
        "        # GNOBlock / neighbor_search expects 2D tensors (N, d)\n",
        "        # so we run per-sample and stack.\n",
        "        for b in range(B):\n",
        "            y = coords[b]        # (N, 2)\n",
        "            x = coords[b]        # (N, 2)\n",
        "            h = feats[b]         # (N, Cin)\n",
        "\n",
        "            # (a) project to hidden dimension\n",
        "            h = self.input_proj(h)    # (N, hidden_channels)\n",
        "\n",
        "            # (b) pass through all GNO blocks, all in/out = hidden_channels\n",
        "            for layer in self.gno_layers:\n",
        "                h = layer(y, x, h)    # all shapes (N, hidden_channels)\n",
        "\n",
        "            # (c) pointwise head to scalar output\n",
        "            h = self.head(h)         # (N, 1)\n",
        "\n",
        "            outputs.append(h.unsqueeze(0))  # (1, N, 1)\n",
        "\n",
        "        # stack back into (B, N, 1)\n",
        "        return torch.cat(outputs, dim=0)\n"
      ],
      "metadata": {
        "id": "vXMAwi90cDZw"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "in_channels = feats0.shape[-1]\n",
        "print(\"Input feature channels:\", in_channels)\n",
        "\n",
        "model = GNOPoissonModel(\n",
        "    in_channels=in_channels,\n",
        "    hidden_channels=17,\n",
        "    coord_dim=2,\n",
        "    radius=0.2,\n",
        "    n_layers=3,\n",
        ").to(device)\n",
        "\n",
        "print(model)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlQVgOGEUUrB",
        "outputId": "02e4fe01-cf1a-4341-97ec-4a75d6f52c6d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input feature channels: 17\n",
            "GNOPoissonModel(\n",
            "  (input_proj): Linear(in_features=17, out_features=17, bias=True)\n",
            "  (gno_layers): ModuleList(\n",
            "    (0-2): 3 x GNOBlock(\n",
            "      (pos_embedding): SinusoidalEmbedding()\n",
            "      (neighbor_search): NeighborSearch()\n",
            "      (integral_transform): IntegralTransform(\n",
            "        (channel_mlp): LinearChannelMLP(\n",
            "          (fcs): ModuleList(\n",
            "            (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (1): Linear(in_features=128, out_features=256, bias=True)\n",
            "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
            "            (3): Linear(in_features=128, out_features=17, bias=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (head): Sequential(\n",
            "    (0): Linear(in_features=17, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-6)\n",
        "criterion = nn.MSELoss()\n"
      ],
      "metadata": {
        "id": "q4DqxcS3U2mo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "\n",
        "print(\"coords0\", type(coords0), coords0.shape)\n",
        "print(\"feats0\", type(feats0))\n",
        "print(\"u0\", type(u0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP0npWdmXUv-",
        "outputId": "84ef82cb-16e4-4681-d605-733fa373e77b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coords0 <class 'torch.Tensor'> torch.Size([4, 256, 2])\n",
            "feats0 <class 'torch.Tensor'>\n",
            "u0 <class 'torch.Tensor'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GNOBlock.forward signature:\\n\")\n",
        "print(inspect.signature(GNOBlock.forward))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxdaaMNgWLO8",
        "outputId": "e56be85c-ebe2-44f4-9664-f25c48e8b37a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNOBlock.forward signature:\n",
            "\n",
            "(self, y, x, f_y=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inspect.getsource(GNOBlock.forward))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Shbuh3qiWgeT",
        "outputId": "be36c747-ff22-4fd6-9529-cfb77dce3160"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    def forward(self, y, x, f_y=None):\n",
            "        \"\"\"Compute a GNO neighbor search and kernel integral transform.\n",
            "\n",
            "        Parameters\n",
            "        ----------\n",
            "        y : torch.Tensor of shape [n, d1]\n",
            "            n points of dimension d1 specifying\n",
            "            the space to integrate over.\n",
            "            If batched, these must remain constant\n",
            "            over the whole batch so no batch dim is needed.\n",
            "        x : torch.Tensor of shape [m, d1], default None\n",
            "            m points of dimension d1 over which the\n",
            "            output function is defined. Must share domain\n",
            "            with y\n",
            "        f_y : torch.Tensor of shape [batch, n, d2] or [n, d2], default None\n",
            "            Function to integrate the kernel against defined\n",
            "            on the points y. The kernel is assumed diagonal\n",
            "            hence its output shape must be d3 for the transforms\n",
            "            (b) or (d). If None, (a) is computed.\n",
            "\n",
            "        Output\n",
            "        ----------\n",
            "        out_features : torch.Tensor of shape [batch, m, d3] or [m, d3]\n",
            "            Output function given on the points x.\n",
            "            d4 is the output size of the kernel k.\n",
            "        \"\"\"\n",
            "        if f_y is not None:\n",
            "            if f_y.ndim == 3 and f_y.shape[0] == -1:\n",
            "                f_y = f_y.squeeze(0)\n",
            "\n",
            "        neighbors_dict = self.neighbor_search(data=y, queries=x, radius=self.radius)\n",
            "\n",
            "        if self.pos_embedding is not None:\n",
            "            y_embed = self.pos_embedding(y)\n",
            "            x_embed = self.pos_embedding(x)\n",
            "        else:\n",
            "            y_embed = y\n",
            "            x_embed = x\n",
            "\n",
            "        out_features = self.integral_transform(\n",
            "            y=y_embed, x=x_embed, neighbors=neighbors_dict, f_y=f_y\n",
            "        )\n",
            "\n",
            "        return out_features\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(inspect.signature(GNOBlock.forward))\n",
        "print(inspect.getsource(GNOBlock.forward))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZSQHPeyWqtf",
        "outputId": "68e937a6-7eb8-4dab-f0cf-38a65716d353"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(self, y, x, f_y=None)\n",
            "    def forward(self, y, x, f_y=None):\n",
            "        \"\"\"Compute a GNO neighbor search and kernel integral transform.\n",
            "\n",
            "        Parameters\n",
            "        ----------\n",
            "        y : torch.Tensor of shape [n, d1]\n",
            "            n points of dimension d1 specifying\n",
            "            the space to integrate over.\n",
            "            If batched, these must remain constant\n",
            "            over the whole batch so no batch dim is needed.\n",
            "        x : torch.Tensor of shape [m, d1], default None\n",
            "            m points of dimension d1 over which the\n",
            "            output function is defined. Must share domain\n",
            "            with y\n",
            "        f_y : torch.Tensor of shape [batch, n, d2] or [n, d2], default None\n",
            "            Function to integrate the kernel against defined\n",
            "            on the points y. The kernel is assumed diagonal\n",
            "            hence its output shape must be d3 for the transforms\n",
            "            (b) or (d). If None, (a) is computed.\n",
            "\n",
            "        Output\n",
            "        ----------\n",
            "        out_features : torch.Tensor of shape [batch, m, d3] or [m, d3]\n",
            "            Output function given on the points x.\n",
            "            d4 is the output size of the kernel k.\n",
            "        \"\"\"\n",
            "        if f_y is not None:\n",
            "            if f_y.ndim == 3 and f_y.shape[0] == -1:\n",
            "                f_y = f_y.squeeze(0)\n",
            "\n",
            "        neighbors_dict = self.neighbor_search(data=y, queries=x, radius=self.radius)\n",
            "\n",
            "        if self.pos_embedding is not None:\n",
            "            y_embed = self.pos_embedding(y)\n",
            "            x_embed = self.pos_embedding(x)\n",
            "        else:\n",
            "            y_embed = y\n",
            "            x_embed = x\n",
            "\n",
            "        out_features = self.integral_transform(\n",
            "            y=y_embed, x=x_embed, neighbors=neighbors_dict, f_y=f_y\n",
            "        )\n",
            "\n",
            "        return out_features\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_epoch(loader, train=True):\n",
        "    if train:\n",
        "        model.train()\n",
        "    else:\n",
        "        model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    n_batches = 0\n",
        "\n",
        "    pbar = tqdm(\n",
        "        loader,\n",
        "        leave=False,\n",
        "        desc=\"Train\" if train else \"Val\"\n",
        "    )\n",
        "\n",
        "    for coords, feats, u in pbar:\n",
        "        coords = coords.to(device)\n",
        "        feats  = feats.to(device)\n",
        "        u      = u.to(device)\n",
        "\n",
        "        if train:\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with torch.set_grad_enabled(train):\n",
        "            u_pred = model(coords, feats)\n",
        "            loss = criterion(u_pred, u)\n",
        "\n",
        "            if train:\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        n_batches += 1\n",
        "\n",
        "        # âœ… Update batch bar only\n",
        "        pbar.set_postfix(\n",
        "            loss=f\"{total_loss / n_batches:.3e}\"\n",
        "        )\n",
        "\n",
        "    return total_loss / max(1, n_batches)"
      ],
      "metadata": {
        "id": "SMCtDxu_iQmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 5\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "epoch_bar = tqdm(\n",
        "    range(1, n_epochs + 1),\n",
        "    desc=\"Epochs\",\n",
        "    position=0\n",
        ")\n",
        "\n",
        "for epoch in epoch_bar:\n",
        "\n",
        "    train_loss = run_epoch(train_loader, train=True)\n",
        "    val_loss   = run_epoch(val_loader,   train=False)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # âœ… Update epoch bar only\n",
        "    epoch_bar.set_postfix({\n",
        "        \"train\": f\"{train_loss:.3e}\",\n",
        "        \"val\":   f\"{val_loss:.3e}\",\n",
        "    })"
      ],
      "metadata": {
        "id": "XIoQ_wFVh7RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = np.arange(1, len(train_losses) + 1)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, train_losses, label=\"Train MSE\", linewidth=2)\n",
        "plt.plot(epochs, val_losses,   label=\"Validation MSE\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Mean Squared Error (MSE)\")\n",
        "plt.title(\"Training and Validation Loss vs Epoch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qeU5UVm4iIJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.semilogy(epochs, train_losses, label=\"Train MSE\", linewidth=2)\n",
        "plt.semilogy(epochs, val_losses,   label=\"Validation MSE\", linewidth=2)\n",
        "\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE (log scale)\")\n",
        "plt.title(\"Training and Validation Loss (Log Scale)\")\n",
        "plt.legend()\n",
        "plt.grid(True, which=\"both\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "PyVo7PeBiU9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(epochs, train_losses, label=\"Train MSE\")\n",
        "plt.plot(epochs, val_losses, label=\"Validation MSE\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"loss_curve.png\", dpi=300)\n",
        "plt.savefig(\"loss_curve.pdf\")\n",
        "plt.close()\n"
      ],
      "metadata": {
        "id": "tvNgBvvxiV-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coords0, feats0, u0 = next(iter(train_loader))\n",
        "print(coords0.shape)\n",
        "print(feats0.shape)\n",
        "print(u0.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6QR2wDsfoP9",
        "outputId": "dfb12d7e-8a90-48e8-c249-e899870a0146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 2048, 2])\n",
            "torch.Size([4, 2048, 17])\n",
            "torch.Size([4, 2048, 1])\n"
          ]
        }
      ]
    }
  ]
}